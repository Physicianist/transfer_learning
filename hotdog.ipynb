{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2dac3f2",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-14T19:41:29.799056Z",
     "iopub.status.busy": "2025-10-14T19:41:29.798820Z",
     "iopub.status.idle": "2025-10-14T19:50:28.618640Z",
     "shell.execute_reply": "2025-10-14T19:50:28.617699Z"
    },
    "papermill": {
     "duration": 538.824066,
     "end_time": "2025-10-14T19:50:28.619964",
     "exception": false,
     "start_time": "2025-10-14T19:41:29.795898",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:00<00:00, 185MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss: 0.1830, Train Acc: 0.9180, Val Acc: 0.9489\n",
      "Epoch 2: Loss: 0.0379, Train Acc: 0.9867, Val Acc: 0.9598\n",
      "Epoch 3: Loss: 0.0085, Train Acc: 0.9978, Val Acc: 0.9576\n",
      "Epoch 4: Loss: 0.0030, Train Acc: 0.9995, Val Acc: 0.9652\n",
      "Epoch 5: Loss: 0.0015, Train Acc: 0.9997, Val Acc: 0.9652\n",
      "Epoch 6: Loss: 0.0011, Train Acc: 0.9997, Val Acc: 0.9652\n",
      "Epoch 7: Loss: 0.0010, Train Acc: 1.0000, Val Acc: 0.9674\n",
      "Epoch 8: Loss: 0.0006, Train Acc: 1.0000, Val Acc: 0.9674\n",
      "Epoch 9: Loss: 0.0004, Train Acc: 1.0000, Val Acc: 0.9674\n",
      "Epoch 10: Loss: 0.0003, Train Acc: 1.0000, Val Acc: 0.9674\n",
      "Epoch 11: Loss: 0.0002, Train Acc: 1.0000, Val Acc: 0.9652\n",
      "Epoch 12: Loss: 0.0002, Train Acc: 1.0000, Val Acc: 0.9674\n",
      "Early stopping at epoch 12\n",
      "F1: 0.959, P: 0.931, R: 0.945\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import urllib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "from skimage import io, transform\n",
    "from torchvision import models\n",
    "from torch.utils.data import Dataset, SubsetRandomSampler\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "device = torch.device(\"cuda:0\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "class HotdogRecognitionDataset(Dataset):\n",
    "    def __init__(self, folder, transform=None):\n",
    "        self.folder = folder\n",
    "        self.transform = transform\n",
    "        self.files = os.listdir(folder)\n",
    "        self.hotdog_prefixes = ['chili-dog', 'frankfurter', 'hotdog']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_name = self.files[index]\n",
    "        img_path = os.path.join(self.folder, img_name)\n",
    "        image = Image.open(img_path)\n",
    "        y = 0\n",
    "        for prefix in self.hotdog_prefixes:\n",
    "            if img_name.startswith(prefix):\n",
    "                y = 1\n",
    "                break\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, y, img_name\n",
    "\n",
    "def visualize_samples(dataset, indices, title=None):\n",
    "    n = len(indices)\n",
    "    fig, axes = plt.subplots(1, n, figsize=(20, 3))\n",
    "    if title:\n",
    "        plt.suptitle(title, fontsize=16)\n",
    "    \n",
    "    for i, index in enumerate(indices):\n",
    "        x, y, img_name = dataset[index]\n",
    "        ax = axes[i]\n",
    "        ax.imshow(x)\n",
    "        ax.set_title(f\"Label: {y}\", fontsize=12)\n",
    "        ax.grid(False)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Путь к обучающим данным\n",
    "train_path = '/kaggle/input/hotdog-dataset-zip/Задание 5. Нейронные сети/train/train_kaggle'\n",
    "test_path = '/kaggle/input/hotdog-dataset-zip/Задание 5. Нейронные сети/test/test_kaggle'\n",
    "\n",
    "train_dataset = HotdogRecognitionDataset(train_path,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.Resize((224, 224)),\n",
    "                           transforms.ToTensor(),\n",
    "                           # Use mean and std for pretrained models\n",
    "                           # https://pytorch.org/docs/stable/torchvision/models.html\n",
    "                           transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "                       ])\n",
    "                      )\n",
    "test_dataset = HotdogRecognitionDataset(test_path,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.Resize((224, 224)),\n",
    "                           transforms.ToTensor(),\n",
    "                           # Use mean and std for pretrained models\n",
    "                           # https://pytorch.org/docs/stable/torchvision/models.html\n",
    "                           transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "                       ])\n",
    "                      )\n",
    "batch_size = 64\n",
    "\n",
    "data_size = len(train_dataset)\n",
    "validation_fraction = .2\n",
    "\n",
    "\n",
    "val_split = int(np.floor((validation_fraction) * data_size))\n",
    "indices = list(range(data_size))\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "val_indices, train_indices = indices[:val_split], indices[val_split:]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "val_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
    "                                           sampler=train_sampler)\n",
    "val_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
    "                                         sampler=val_sampler)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "def compute_accuracy(model, loader):\n",
    "    model.eval()  # Enter evaluation mode\n",
    "    correct_samples = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y, _ in loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            predictions = model(x)\n",
    "            correct_samples += (predictions.argmax(dim=1) == y).sum().item()\n",
    "            total_samples += y.size(0)\n",
    "\n",
    "    return correct_samples / total_samples\n",
    "\n",
    "def train_model_with_early_stopping(model, train_loader, val_loader, loss, optimizer, num_epochs, patience=5):\n",
    "    best_val_acc = 0\n",
    "    patience_counter = 0\n",
    "    best_model_state = None\n",
    "    \n",
    "    loss_history = []\n",
    "    train_history = []\n",
    "    val_history = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        loss_accum = 0\n",
    "        correct_samples = 0\n",
    "        total_samples = 0\n",
    "        \n",
    "        for i_step, (x, y, _) in enumerate(train_loader):\n",
    "            x_gpu = x.to(device)\n",
    "            y_gpu = y.to(device)\n",
    "            \n",
    "            prediction = model(x_gpu)\n",
    "            loss_value = loss(prediction, y_gpu)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss_value.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            _, indices = torch.max(prediction, 1)\n",
    "            correct_samples += torch.sum(indices == y_gpu).item()\n",
    "            total_samples += y.shape[0]\n",
    "            loss_accum += loss_value.item()\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        ave_loss = loss_accum / len(train_loader)\n",
    "        train_accuracy = correct_samples / total_samples\n",
    "        val_accuracy = compute_accuracy(model, val_loader)\n",
    "        \n",
    "        loss_history.append(ave_loss)\n",
    "        train_history.append(train_accuracy)\n",
    "        val_history.append(val_accuracy)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}: Loss: {ave_loss:.4f}, Train Acc: {train_accuracy:.4f}, Val Acc: {val_accuracy:.4f}\")\n",
    "        \n",
    "        # Ранняя остановка\n",
    "        if val_accuracy > best_val_acc:\n",
    "            best_val_acc = val_accuracy\n",
    "            best_model_state = model.state_dict().copy()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            \n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "            \n",
    "    model.load_state_dict(best_model_state)\n",
    "    return loss_history, train_history, val_history\n",
    "\n",
    "# Thanks to https://discuss.pytorch.org/t/imagenet-classes/4923/2\n",
    "def load_imagenet_classes():\n",
    "    classes_json = urllib.request.urlopen('https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json').read()\n",
    "    classes = json.loads(classes_json)\n",
    "\n",
    "    #Process it to return dict of class index to name\n",
    "    return { int(k): v[-1] for k, v in classes.items()}\n",
    "\n",
    "def visualize_resnet_predictions(model, dataset, num_samples=10):\n",
    "    \"\"\"\n",
    "    Тестирует ResNet18 на случайных изображениях и визуализирует предсказания\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    # Загружаем классы ImageNet\n",
    "    imagenet_classes = load_imagenet_classes()\n",
    "    indices = np.random.choice(len(dataset), num_samples, replace=False)\n",
    "    plt.figure(figsize=(20, 8))\n",
    "\n",
    "    for i, idx in enumerate(indices):\n",
    "        image_tensor, true_label, filename = dataset[idx]\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Добавляем размерность батча и перемещаем на устройство\n",
    "            prediction = model(image_tensor.unsqueeze(0).to(device))\n",
    "            values, indices = torch.max(prediction, 1)\n",
    "        \n",
    "        pred_class_idx = indices.item()\n",
    "        pred_class_name = imagenet_classes[pred_class_idx]\n",
    "        confidence = torch.softmax(prediction, dim=1)[0][pred_class_idx].item()\n",
    "        \n",
    "        # Денормализуем изображение для отображения\n",
    "        mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "        std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "        image_denorm = image_tensor * std + mean\n",
    "        image_denorm = torch.clamp(image_denorm, 0, 1)\n",
    "        image_np = image_denorm.permute(1, 2, 0).numpy()\n",
    "\n",
    "        plt.subplot(2, 5, i + 1)\n",
    "        plt.imshow(image_np)\n",
    "        plt.title(f\"True: {'Hotdog' if true_label == 1 else 'Not Hotdog'}\\nPred: {pred_class_name}\\nConf: {confidence:.3f}\")\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "#Тренируем только последний слой\n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False\n",
    "# model.fc = nn.Linear(512, 2)\n",
    "# model.fc = model.fc.to(device)\n",
    "# loss = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD( model.parameters(), lr=0.001, momentum=0.9)\n",
    "# loss_history, train_history, val_history = train_model(model, train_loader, val_loader, loss, optimizer, 2)\n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "model = model.to(device)\n",
    "#Тренируем всю модель\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 2)\n",
    "model.fc = model.fc.to(device)\n",
    "# Разные learning rates для разных частей\n",
    "parameters = [\n",
    "    {'params': model.fc.parameters(), 'lr': 0.001},  # Быстрее обучаем новый слой\n",
    "    {'params': [p for n, p in model.named_parameters() if 'fc' not in n], 'lr': 0.0001}]\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(parameters, lr=0.001, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=15)\n",
    "loss_history, train_history, val_history = train_model_with_early_stopping(\n",
    "    model, train_loader, val_loader, loss, optimizer, 20, patience=5\n",
    ")\n",
    "\n",
    "from torch.utils.data.sampler import Sampler\n",
    "from torch.utils.data import DataLoader\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "class SubsetSampler(Sampler):\n",
    "\n",
    "    def __init__(self, indices):\n",
    "        self.indices = indices\n",
    "\n",
    "    def __iter__(self):\n",
    "        return (self.indices[i] for i in range(len(self.indices)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "        \n",
    "def evaluate_model(model, dataset, indices):\n",
    "    sampler = SubsetSampler(indices)\n",
    "    loader = DataLoader(dataset, batch_size=32, sampler=sampler)\n",
    "    all_predictions = []\n",
    "    all_ground_truth = []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            x, y, _ = batch\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            outputs = model(x)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_ground_truth.extend(y.cpu().numpy())\n",
    "            \n",
    "    predictions = np.array(all_predictions, dtype=bool)\n",
    "    ground_truth = np.array(all_ground_truth, dtype=bool)\n",
    "    return predictions, ground_truth\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def binary_classification_metrics(prediction, ground_truth):\n",
    "    prediction_int = prediction.astype(int)\n",
    "    ground_truth_int = ground_truth.astype(int)\n",
    "    precision = metrics.precision_score(ground_truth_int, prediction_int)\n",
    "    recall = metrics.recall_score(ground_truth_int, prediction_int)\n",
    "    f1 = metrics.f1_score(ground_truth_int, prediction_int)\n",
    "    return precision, recall, f1\n",
    "\n",
    "predictions, ground_truth = evaluate_model(model, train_dataset, val_indices)\n",
    "precision, recall, f1 = binary_classification_metrics(predictions, ground_truth)\n",
    "print(\"F1: %4.3f, P: %4.3f, R: %4.3f\" % (precision, recall, f1))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8488902,
     "sourceId": 13379631,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 546.743427,
   "end_time": "2025-10-14T19:50:31.370376",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-14T19:41:24.626949",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
